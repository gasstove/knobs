\color{red}{\emph{Keywords and ideas: non-convex, ruggued search landscape(i.e.:sharp bends, discontinuities, outliers, noise, local optima), badly scaled and/or highly non-separable, convergence, adaptive, Black-Box, evaluated search points are the only accessible information on f, Randomized/stochastic works well, Robust, imputation, continuous domain.}}
\color{black}

The performance errors are irregular functions. In particular, the congestion pattern fitting reflects congestion phenomena. These present numerous thresholds in their non-smooth behavior.\\
We can also point out that these errors aren't always correlated.\\
Furthermore, each evaluation of the error function requires the execution of a simulation (around 5 seconds on a desktop computer), and this evaluation is the only thing accessible of $\Phi$: there is no way of quickly computing its value or its gradient .\\
Therefore, the objective function is a black box.\\
We deduce from these observations that convex optimization methods and derivative-based methods are not adapted to our case.\\
The search space is a continuous hyper-cube, as explained in \ref{subsubsec:naive}.\\
We can conclude that we study a non-linear, non-convex black-box imputation problem in continuous domain.\\
\\ 	
In addition, the resolution method has to be adaptive, since it will be applied to many different freeways, times and sensor densities. We want as few numerical method parameters to tune as possible and  no prior optimization knowledge required if possible.\\
\\
%	\item What kind of algorithm is suitable
Finally, this experiment is a proof of concept that does not take execution time as a criteria : the goal is to obtain the best possible result quality and uniqueness (global minimum of $\Phi$).
